{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 6878184,
     "sourceType": "datasetVersion",
     "datasetId": 3951997
    },
    {
     "sourceId": 6878983,
     "sourceType": "datasetVersion",
     "datasetId": 3952354
    },
    {
     "sourceId": 7015358,
     "sourceType": "datasetVersion",
     "datasetId": 4033505
    }
   ],
   "dockerImageVersionId": 30559,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import re\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-22T09:02:35.188559Z",
     "iopub.execute_input": "2023-11-22T09:02:35.188962Z",
     "iopub.status.idle": "2023-11-22T09:02:38.944722Z",
     "shell.execute_reply.started": "2023-11-22T09:02:35.188931Z",
     "shell.execute_reply": "2023-11-22T09:02:38.943642Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/kaggle/input/full-quora-csv/questions.csv\")\n",
    "df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:02:38.946490Z",
     "iopub.execute_input": "2023-11-22T09:02:38.946896Z",
     "iopub.status.idle": "2023-11-22T09:02:40.984293Z",
     "shell.execute_reply.started": "2023-11-22T09:02:38.946868Z",
     "shell.execute_reply": "2023-11-22T09:02:40.983248Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "execution_count": 2,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id    qid1    qid2  \\\n0            0       1       2   \n1            1       3       4   \n2            2       5       6   \n3            3       7       8   \n4            4       9      10   \n...        ...     ...     ...   \n404346  404346  789792  789793   \n404347  404347  789794  789795   \n404348  404348  789796  789797   \n404349  404349  789798  789799   \n404350  404350  789800  789801   \n\n                                                question1  \\\n0       What is the step by step guide to invest in sh...   \n1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2       How can I increase the speed of my internet co...   \n3       Why am I mentally very lonely? How can I solve...   \n4       Which one dissolve in water quikly sugar, salt...   \n...                                                   ...   \n404346  How many keywords are there in the Racket prog...   \n404347          Do you believe there is life after death?   \n404348                                  What is one coin?   \n404349  What is the approx annual cost of living while...   \n404350              What is like to have sex with cousin?   \n\n                                                question2  is_duplicate  \n0       What is the step by step guide to invest in sh...             0  \n1       What would happen if the Indian government sto...             0  \n2       How can Internet speed be increased by hacking...             0  \n3       Find the remainder when [math]23^{24}[/math] i...             0  \n4                 Which fish would survive in salt water?             0  \n...                                                   ...           ...  \n404346  How many keywords are there in PERL Programmin...             0  \n404347         Is it true that there is life after death?             1  \n404348                                  What's this coin?             0  \n404349  I am having little hairfall problem but I want...             0  \n404350      What is it like to have sex with your cousin?             0  \n\n[404351 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404346</th>\n      <td>404346</td>\n      <td>789792</td>\n      <td>789793</td>\n      <td>How many keywords are there in the Racket prog...</td>\n      <td>How many keywords are there in PERL Programmin...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>404347</th>\n      <td>404347</td>\n      <td>789794</td>\n      <td>789795</td>\n      <td>Do you believe there is life after death?</td>\n      <td>Is it true that there is life after death?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>404348</th>\n      <td>404348</td>\n      <td>789796</td>\n      <td>789797</td>\n      <td>What is one coin?</td>\n      <td>What's this coin?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>404349</th>\n      <td>404349</td>\n      <td>789798</td>\n      <td>789799</td>\n      <td>What is the approx annual cost of living while...</td>\n      <td>I am having little hairfall problem but I want...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>404350</th>\n      <td>404350</td>\n      <td>789800</td>\n      <td>789801</td>\n      <td>What is like to have sex with cousin?</td>\n      <td>What is it like to have sex with your cousin?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>404351 rows × 6 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.word2index = {}  # sets index accodringly to unique ness - most common lower index e.g.1 \n",
    "        self.word2count = {}  # counts each unique word \n",
    "        self.index2word = {}  # reverse of word2index\n",
    "        self.n_words = 0\n",
    "        # self.questions_pair, self.labels = self.convert_data_to_tuples(df, False, False)\n",
    "        self.questions_pair = []\n",
    "        self.labels = []\n",
    "        self.convert_data_to_tuples(self.df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions_pair)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        questions = self.questions_pair[index]\n",
    "        if questions:\n",
    "            q1 = questions[0]\n",
    "            q1_indices = []\n",
    "            for word in q1.split():\n",
    "                q1_indices.append(self.word2index[word])\n",
    "\n",
    "            q2 = questions[1]\n",
    "            q2_indices = []\n",
    "            for word in q2.split():\n",
    "                q2_indices.append(self.word2index[word])\n",
    "\n",
    "            return {\n",
    "                'q1': q1,\n",
    "                'q2': q2,\n",
    "                'q1_token': q1_indices, \n",
    "                'q2_token': q2_indices, \n",
    "                'labels': self.labels[index], \n",
    "            }\n",
    "\n",
    "    \n",
    "    def text_to_wordlist(self, text, remove_stopwords = False, stem_words = False):\n",
    "        text = text.lower().split()\n",
    "\n",
    "        # Optionally, remove stop words\n",
    "        if remove_stopwords:\n",
    "            stops = set(stopwords.words(\"english\"))\n",
    "            text = [w for w in text if not w in stops]\n",
    "\n",
    "        text = \" \".join(text)\n",
    "\n",
    "        # Clean the text\n",
    "        text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "        text = re.sub(r\"what's\", \"what is \", text)\n",
    "        text = re.sub(r\"\\'s\", \" \", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "        text = re.sub(r\"can't\", \"cannot \", text)\n",
    "        text = re.sub(r\"n't\", \" not \", text)\n",
    "        text = re.sub(r\"i'm\", \"i am \", text)\n",
    "        text = re.sub(r\"\\'re\", \" are \", text)\n",
    "        text = re.sub(r\"\\'d\", \" would \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "        text = re.sub(r\",\", \" \", text)\n",
    "        text = re.sub(r\"\\.\", \" \", text)\n",
    "        text = re.sub(r\"!\", \" ! \", text)\n",
    "        text = re.sub(r\"\\/\", \" \", text)\n",
    "        text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "        text = re.sub(r\"\\+\", \" + \", text)\n",
    "        text = re.sub(r\"\\-\", \" - \", text)\n",
    "        text = re.sub(r\"\\=\", \" = \", text)\n",
    "        text = re.sub(r\"'\", \" \", text)\n",
    "        text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "        text = re.sub(r\":\", \" : \", text)\n",
    "        text = re.sub(r\" e g \", \" eg \", text)\n",
    "        text = re.sub(r\" b g \", \" bg \", text)\n",
    "        text = re.sub(r\" u s \", \" american \", text)\n",
    "        text = re.sub(r\"\\0s\", \"0\", text)\n",
    "        text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "        text = re.sub(r\"e - mail\", \"email\", text)\n",
    "        text = re.sub(r\"j k\", \"jk\", text)\n",
    "        text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "        # Optionally, shorten words to their stems\n",
    "        if stem_words:\n",
    "            text = text.split()\n",
    "            stemmer = SnowballStemmer('english')\n",
    "            stemmed_words = [stemmer.stem(word) for word in text]\n",
    "            text = \" \".join(stemmed_words)\n",
    "\n",
    "        # Return a list of words\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words + 1\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words + 1] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    \n",
    "    def convert_data_to_tuples(self, df, remove_stopwords = False, stem_words = False):\n",
    "        for i, row in df.iterrows():\n",
    "            q1 = self.text_to_wordlist(str(row['question1']), remove_stopwords = False, stem_words = False)\n",
    "            q2 = self.text_to_wordlist(str(row['question2']), remove_stopwords = False, stem_words = False)\n",
    "            self.add_sentence(q1)\n",
    "            self.add_sentence(q2)\n",
    "            label = int(row['is_duplicate'])\n",
    "            if q1 and q2:\n",
    "                self.questions_pair.append((q1, q2))\n",
    "                self.labels.append(label)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:02:40.986056Z",
     "iopub.execute_input": "2023-11-22T09:02:40.986419Z",
     "iopub.status.idle": "2023-11-22T09:02:41.010053Z",
     "shell.execute_reply.started": "2023-11-22T09:02:40.986385Z",
     "shell.execute_reply": "2023-11-22T09:02:41.009169Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = QuoraDataset(df)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:02:41.012762Z",
     "iopub.execute_input": "2023-11-22T09:02:41.013111Z",
     "iopub.status.idle": "2023-11-22T09:04:02.459294Z",
     "shell.execute_reply.started": "2023-11-22T09:02:41.013079Z",
     "shell.execute_reply": "2023-11-22T09:04:02.458480Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(dataset.questions_pair))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:02.460497Z",
     "iopub.execute_input": "2023-11-22T09:04:02.460786Z",
     "iopub.status.idle": "2023-11-22T09:04:02.465894Z",
     "shell.execute_reply.started": "2023-11-22T09:04:02.460760Z",
     "shell.execute_reply": "2023-11-22T09:04:02.464995Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "404331\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def collate(batch):\n",
    "    q1_text_list = []\n",
    "    q2_text_list = []\n",
    "    q1_list = []\n",
    "    q2_list = []\n",
    "    labels = []\n",
    "    for item in batch:\n",
    "        q1_text_list.append(item['q1'])\n",
    "        q2_text_list.append(item['q2'])\n",
    "        q1_list.append(item['q1_token'])\n",
    "        q2_list.append(item['q2_token'])\n",
    "        labels.append(item['labels'])\n",
    "          \n",
    "        \n",
    "    q1_lengths = [len(q) for q in q1_list]\n",
    "    q2_lengths = [len(q) for q in q2_list]\n",
    "    \n",
    "    return {\n",
    "        'q1_text': q1_text_list,\n",
    "        'q2_text': q2_text_list, \n",
    "        'q1_token': q1_list, \n",
    "        'q2_token': q2_list,\n",
    "        'q1_lengths': q1_lengths, \n",
    "        'q2_lengths': q2_lengths,\n",
    "        'labels': labels\n",
    "    }"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:02.466996Z",
     "iopub.execute_input": "2023-11-22T09:04:02.467263Z",
     "iopub.status.idle": "2023-11-22T09:04:02.478681Z",
     "shell.execute_reply.started": "2023-11-22T09:04:02.467239Z",
     "shell.execute_reply": "2023-11-22T09:04:02.477735Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "train_split = 0.8\n",
    "val_split = 0.2\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "split_train = int(train_split*dataset_size)\n",
    "\n",
    "shuffle_dataset = True\n",
    "random_seed = 46\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[:split_train], indices[split_train:]\n",
    "\n",
    "assert len(train_indices) + len(val_indices) == dataset_size\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, collate_fn=collate)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, collate_fn=collate)\n",
    "\n",
    "print('Training Set Size {}, Validation Set Size {},'.format(len(train_indices), len(val_indices)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:02.479601Z",
     "iopub.execute_input": "2023-11-22T09:04:02.479847Z",
     "iopub.status.idle": "2023-11-22T09:04:02.535302Z",
     "shell.execute_reply.started": "2023-11-22T09:04:02.479825Z",
     "shell.execute_reply": "2023-11-22T09:04:02.534428Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "Training Set Size 323464, Validation Set Size 80867,\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class EmbeddingLSTMNet(nn.Module):\n",
    "    def __init__(self, num_vocab, embedding_dim, hidden_cells,\n",
    "                 num_layers, embedding_rquires_grad, dropout):\n",
    "        super(EmbeddingLSTMNet, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size=embedding_dim, \n",
    "                            hidden_size=hidden_cells, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True\n",
    "                            )\n",
    "        self.fc1 = nn.Linear(hidden_cells, hidden_cells)\n",
    "        self.fc2 = nn.Linear(hidden_cells, hidden_cells)\n",
    "        self.relu = nn.ReLU()\n",
    "        # initialize embeddings \n",
    "        # self.embedding = nn.Embedding.from_pretrained(pretrained_weights)\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_vocab + 1, embedding_dim=embedding_dim)\n",
    "        self.embedding.weight.requires_grad = embedding_rquires_grad\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, question, lengths):\n",
    "        \"\"\" \n",
    "        Params:\n",
    "        -------\n",
    "        question : (batch dim, sequence)\n",
    "                   i.e. [ [i1, i2, i3],\n",
    "                          [j1, j2, j4, j5] ]\n",
    "        lenghts : list\n",
    "                  list all the lengths of each question  \n",
    "        \n",
    "        Return:\n",
    "        -------\n",
    "        result : torch.tensor\n",
    "                 output tesnor of of forward pass \n",
    "        \"\"\"\n",
    "        # Reverse the sequence lengths indices in decreasing order (pytorch requirement for pad and pack)\n",
    "        sorted_indices = np.flipud(np.argsort(lengths))\n",
    "        lengths = np.flipud(np.sort(lengths))\n",
    "        lengths = lengths.copy()\n",
    "        \n",
    "        # Reorder questions in the decreasing order of their lengths\n",
    "        ordered_questions = [torch.LongTensor(question[i]).to(self.device) for i in sorted_indices]\n",
    "        # Pad sequences with 0s to the max length sequence in the batch\n",
    "        ordered_questions = pad_sequence(ordered_questions, batch_first=True)\n",
    "        # Retrieve Embeddings\n",
    "        embeddings = self.embedding(ordered_questions).to(self.device)\n",
    "        \n",
    "        \n",
    "        # Model forward \n",
    "        embeddings = self.dropout(embeddings)\n",
    "        # Pack the padded sequences and pass it through LSTM\n",
    "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True)\n",
    "        out, (hn, cn) = self.lstm(packed)\n",
    "        # Unpack the padded sequence and pass it through the linear layers \n",
    "        unpacked, unpacked_len = pad_packed_sequence(out, batch_first=True, total_length=int(lengths[0]))\n",
    "        out = self.fc1(unpacked)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Reorder the output to the original order in which the questions were passed\n",
    "        result = torch.FloatTensor(out.size())\n",
    "        for i, encoded_matrix in enumerate(out):\n",
    "            result[sorted_indices[i]] = encoded_matrix\n",
    "        return result\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_lstm_net):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \"\"\"\n",
    "        Siamese LSTM Network \n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "        embedding_lstm_net : nn.Module embedded LSTM Network \n",
    "        \"\"\"\n",
    "        self.embedding = embedding_lstm_net\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def forward(self, q1, q2, q1_lengths, q2_lengths):\n",
    "        \"\"\" Forward pass \n",
    "        Params:\n",
    "        -------\n",
    "        q1 : pad sequence tensor question 1  \n",
    "        q2 : pad sequence tensor question 2  \n",
    "        q1_lengths : torch.tensor original lengths of each question 1\n",
    "        q2_lengths : torch.tensor original lengths of each question 1\n",
    "        Returns:\n",
    "        --------\n",
    "        similarity_score : torch.tensor\n",
    "        \"\"\"\n",
    "        output_q1 = self.embedding(q1, q1_lengths)\n",
    "        output_q2 = self.embedding(q2, q2_lengths)\n",
    "        similarity_score = torch.zeros(output_q1.size()[0]).to(self.device)\n",
    "        # Calculate Similarity Score between both questions in a single pair\n",
    "        for index in range(output_q1.size()[0]):\n",
    "            # Sequence lenghts are being used to index and retrieve the activations before the zero padding since they were not part of original question\n",
    "            q1 = output_q1[index, q1_lengths[index] - 1, :]\n",
    "            q2 = output_q2[index, q2_lengths[index] - 1, :]\n",
    "            similarity_score[index] = self.manhattan_distance(q1, q2)\n",
    "        \n",
    "        return similarity_score\n",
    "    \n",
    "    def manhattan_distance(self, q1, q2):\n",
    "        \"\"\" Computes the Mannhatten distance between the two question tokens \"\"\"\n",
    "        return torch.exp(-torch.sum(torch.abs(q1 - q2), dim=0)).to(self.device)\n",
    "    def cosine_similarity(self, q1, q2):\n",
    "        cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "        return cos(q1, q1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:02.536914Z",
     "iopub.execute_input": "2023-11-22T09:04:02.537248Z",
     "iopub.status.idle": "2023-11-22T09:04:02.566992Z",
     "shell.execute_reply.started": "2023-11-22T09:04:02.537216Z",
     "shell.execute_reply": "2023-11-22T09:04:02.565977Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_vocab = len(dataset.word2index)\n",
    "embedding_dim = 300\n",
    "hidden_cells = 100\n",
    "num_layers = 3\n",
    "embedding_rquires_grad = False\n",
    "dropout = 0.0\n",
    "\n",
    "# embedding net\n",
    "embedding_net = EmbeddingLSTMNet(\n",
    "    num_vocab = num_vocab,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_cells = hidden_cells,\n",
    "    num_layers = num_layers,\n",
    "    embedding_rquires_grad = embedding_rquires_grad,\n",
    "    dropout = dropout)\n",
    "\n",
    "# siamese model\n",
    "model = SiameseNetwork(embedding_net).to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:02.568254Z",
     "iopub.execute_input": "2023-11-22T09:04:02.568610Z",
     "iopub.status.idle": "2023-11-22T09:04:08.873765Z",
     "shell.execute_reply.started": "2023-11-22T09:04:02.568575Z",
     "shell.execute_reply": "2023-11-22T09:04:08.872976Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test model class with one batch from the dataloader \n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "model(q1, q2, q1_len, q2_len)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:08.877009Z",
     "iopub.execute_input": "2023-11-22T09:04:08.877294Z",
     "iopub.status.idle": "2023-11-22T09:04:14.507386Z",
     "shell.execute_reply.started": "2023-11-22T09:04:08.877268Z",
     "shell.execute_reply": "2023-11-22T09:04:14.506402Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "execution_count": 10,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0.7516, 0.8349, 0.8511, 0.7871, 0.8032, 0.8300, 0.7910, 0.7947],\n       device='cuda:0', grad_fn=<CopySlices>)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Trainer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self, model, hparams, train_dataloader, val_dataloader, \n",
    "        train_indices, val_indices,lr_scheduler_enabler=True):\n",
    "        \"\"\" \n",
    "        This Class fits the model \n",
    "\n",
    "        Params:\n",
    "        -------  \n",
    "        model : nn.Module\n",
    "                Pytorch NN Model that is spposed to be fitted/trained\n",
    "        hparams : dict\n",
    "                  Dictionary of Hyperparametes  \n",
    "        train_dataloader : torch.utils.data.DataLoader\n",
    "                           Training DataLoader\n",
    "        val_dataloader : torch.utils.data.DataLoader\n",
    "                         Validation DataLoader \n",
    "        train_indices : list \n",
    "                        list of the train indices\n",
    "        val_indices : list\n",
    "                      list of the val indices \n",
    "        lr_scheduler_enabler : bool\n",
    "                               if True enables Learning rate scheduler, if False disables it\n",
    "        \"\"\"\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.lr_scheduler_enabler = lr_scheduler_enabler\n",
    "        self.hparams = hparams \n",
    "        self.learning_rate = hparams['learning_rate']\n",
    "        self.epochs = hparams['epoch']\n",
    "        self.train_indices = train_indices\n",
    "        self.val_indices = val_indices\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        if self.device == \"cuda\":\n",
    "            self.threshold = hparams['threshold'].to(self.device)\n",
    "        else:\n",
    "            self.threshold = hparams['threshold'].to(self.device)\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = self.optimization()\n",
    "        self.loss_fn = self.loss()\n",
    "        self.lr_scheduler = self.learning_rate_scheduler() \n",
    "\n",
    "        self.data = dict()\n",
    "        self.data[\"train_loss\"] = list()\n",
    "        self.data[\"train_acc\"] = list()\n",
    "        self.data[\"val_loss\"] = list()\n",
    "        self.data[\"val_acc\"] = list()\n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\" Trains an epoch \"\"\"\n",
    "        self.model.train()\n",
    "\n",
    "        loss_history = []\n",
    "        correct_total = 0\n",
    "        with tqdm(self.train_dataloader, unit=\"batch\") as tepoch:\n",
    "            for i, batch in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch [{epoch+1}/{self.epochs}]  Training\")\n",
    "                if self.device == \"cuda\":\n",
    "                    q1, q2 = batch['q1_token'].to(self.device), batch['q2_token'].to(self.device)\n",
    "                    q1_len, q2_len = batch['q1_lengths'].to(self.device), batch['q2_lengths'].to(self.device)\n",
    "                    y = torch.FloatTensor(batch['labels']).to(self.device)\n",
    "                else:\n",
    "                    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "                    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "                    y = torch.FloatTensor(batch['labels'])\n",
    "                \n",
    "                # Reset the gardients \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Model forward and predictions\n",
    "                similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "                y_pred = (similarity > self.threshold).float() * 1\n",
    "                y = y.to(\"cuda\")\n",
    "                correct = self.inferece(y_pred, y)\n",
    "                correct_total += correct\n",
    "\n",
    "                # Calculate the loss \n",
    "                loss = self.loss_fn(similarity, y)\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "                # Calculate gradients by performign the backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    tepoch.set_postfix(train_loss=np.mean(loss_history), train_acc=f'{(correct/y.size()[0])*100} %' )\n",
    "            \n",
    "            # Enable learning rate scheduler  \n",
    "            if self.lr_scheduler_enabler:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "        return  np.mean(loss_history), (correct_total/len(self.train_indices))*100\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\" Validates an epoch \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        loss_history = []\n",
    "        correct_total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.val_dataloader):\n",
    "                if self.device == \"cuda\":\n",
    "                    q1, q2 = batch['q1_token'].to(self.device), batch['q2_token'].to(self.device)\n",
    "                    q1_len, q2_len = batch['q1_lengths'].to(self.device), batch['q2_lengths'].to(self.device)\n",
    "                    y = torch.FloatTensor(batch['labels']).to(self.device)\n",
    "                else:\n",
    "                    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "                    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "                    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "                # Model forward and predictions\n",
    "                similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "                y_pred = (similarity > self.threshold).float() * 1\n",
    "                correct = self.inferece(y_pred, y)\n",
    "                correct_total += correct\n",
    "\n",
    "                # Calculate the loss\n",
    "                y = y.to(\"cuda\")\n",
    "                loss = self.loss_fn(similarity, y)\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "        avg_val_acc =  correct_total/len(self.val_indices) * 100 \n",
    "        return np.mean(loss_history), avg_val_acc\n",
    "    \n",
    "    def inferece(self, y_pred, y):\n",
    "        \"\"\" Performs inference \"\"\"\n",
    "        y = y.to(\"cuda\")\n",
    "        return (y_pred == y).sum().item()\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\" Fits the model \"\"\"\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        best_acc = 0\n",
    "        index_model = 0\n",
    "        for e in range(self.epochs):\n",
    "            train_loss, train_acc = self.train_epoch(e)\n",
    "            val_loss, val_acc = self.evaluate()\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                PATH = f\"Model_{index_model}_val_acc_{best_acc}\"\n",
    "                torch.save(self.model.state_dict(), PATH)\n",
    "                index_model += 1\n",
    "                \n",
    "            print(f'Epoch [{e+1}/{self.epochs}] Validation: val_loss: {val_loss} val_acc: {val_acc} %')\n",
    "            \n",
    "            self.data[\"train_loss\"].append(train_loss)\n",
    "            self.data[\"train_acc\"].append(train_acc)\n",
    "            self.data[\"val_loss\"].append(val_loss)\n",
    "            self.data[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\" Tests the model \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        labels_list = []\n",
    "        loss_history = []\n",
    "        correct_total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.val_dataloader):\n",
    "                if self.device == \"cuda\":\n",
    "                    q1, q2 = batch['q1_token'].to(self.device), batch['q2_token'].to(self.device)\n",
    "                    q1_len, q2_len = batch['q1_lengths'].to(self.device), batch['q2_lengths'].to(self.device)\n",
    "                    y = torch.FloatTensor(batch['labels']).to(self.device)\n",
    "                else:\n",
    "                    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "                    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "                    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "                # Model forward and predictions\n",
    "                similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "                y_pred = (similarity > self.threshold).float() * 1\n",
    "                predictions.append(y_pred), labels_list.append(y)\n",
    "                correct = self.inferece(y_pred, y)\n",
    "                correct_total += correct\n",
    "\n",
    "                # Calculate the loss \n",
    "                \n",
    "                loss = self.loss_fn(similarity, y)\n",
    "                loss_history.append(loss.item())\n",
    "        \n",
    "        # Calculate the accuracy\n",
    "        avg_val_acc =  correct_total/len(self.val_indices) * 100 \n",
    "        print('- - - Model Performance - - -')\n",
    "        print(f'\\nModel Accuracy:  {avg_val_acc}')\n",
    "        print(f'Correct predictions: {correct_total}, Incorret predictions: {len(self.val_indices) - correct_total}')\n",
    "        print('')\n",
    "        cm = plotConfusionMatrix(np.hstack(predictions), np.hstack(labels_list),['similar', 'dissimilar'], title=\"Confusion Matrix Plot of Test Set\")\n",
    "        print(f'TP: {cm[0,0]}')\n",
    "        print(f'FP: {cm[1,0]}')\n",
    "        print(f'FN: {cm[0,1]}')\n",
    "        print(f'TN: {cm[1,1]}')\n",
    "        print(f'\\nPrecision Score: {precision_score(np.hstack(predictions), np.hstack(labels_list))}')\n",
    "        print(f'Recall Score: {recall_score(np.hstack(predictions), np.hstack(labels_list))}')\n",
    "        print(f'F1 Score: {f1_score(np.hstack(predictions), np.hstack(labels_list))}')\n",
    "\n",
    "        # adopted from https://www.codegrepper.com/code-examples/python/roc+curve+pytorch\n",
    "        fpr, tpr, threshold = roc_curve(np.hstack(predictions), np.hstack(labels_list))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        # adopted from https://www.codegrepper.com/code-examples/python/roc+curve+pytorch\n",
    "\n",
    "    def predict(self, test_sample_dict):\n",
    "        \"\"\" Uses the model to predict the similarity of a given input pair of questions\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        print('question 1:', test_sample_dict['q1_text'])\n",
    "        print('question 2:', test_sample_dict['q2_text'])\n",
    "        print('tokens  q1:', test_sample_dict['q1_token'])\n",
    "        print('tokens  q2:', test_sample_dict['q2_token'])\n",
    "\n",
    "        q1, q2 = test_sample_dict['q1_token'], test_sample_dict['q2_token']\n",
    "        q1_len, q2_len = test_sample_dict['q1_lengths'], test_sample_dict['q2_lengths']\n",
    "        y = torch.FloatTensor(test_sample_dict['labels'])\n",
    "        \n",
    "        # Model forward and predictions\n",
    "        similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "        y_pred = (similarity > self.threshold).float() * 1\n",
    "        \n",
    "        print(f'\\n\\nModel predicts {y_pred.item()} --> Actual value {y.item()}')\n",
    "        if y_pred.item() == y.item():\n",
    "            print(f'Model prediction is correct :)')\n",
    "\n",
    "            if y_pred.item() == 1.0:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} are similar!')\n",
    "            else:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} are dissimilar!')    \n",
    "        else:\n",
    "            print(f'Model prediction is inaccurate :(')\n",
    "            if y_pred.item() == 1.0:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} should be dissimilar!')\n",
    "            else:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} should be similar!')  \n",
    "        \n",
    "    def optimization(self):\n",
    "        \"\"\" Initializes the optimizer \"\"\"\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def learning_rate_scheduler(self):\n",
    "        \"\"\" Initializes the learning rate scheduler \"\"\"\n",
    "        return torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.9)\n",
    "\n",
    "    def loss(self):\n",
    "        \"\"\" Initializes the loss \"\"\"\n",
    "        return nn.MSELoss() #nn.CrossEntropyLoss()\n",
    "    \n",
    "    def return_data(self):\n",
    "        \"\"\" Output the data \"\"\"\n",
    "        return self.data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:14.509209Z",
     "iopub.execute_input": "2023-11-22T09:04:14.509620Z",
     "iopub.status.idle": "2023-11-22T09:04:14.553539Z",
     "shell.execute_reply.started": "2023-11-22T09:04:14.509584Z",
     "shell.execute_reply": "2023-11-22T09:04:14.552568Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hparams = {\n",
    "    'threshold': torch.Tensor([0.5]),  # threshold for determining similiarity\n",
    "    'learning_rate': 1e-03,  # learning rate\n",
    "    'epoch': 10  # number of epochs\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:14.554975Z",
     "iopub.execute_input": "2023-11-22T09:04:14.555289Z",
     "iopub.status.idle": "2023-11-22T09:04:14.568030Z",
     "shell.execute_reply.started": "2023-11-22T09:04:14.555266Z",
     "shell.execute_reply": "2023-11-22T09:04:14.567232Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = ModelTrainer(\n",
    "    model, \n",
    "    hparams, \n",
    "    train_dataloader, \n",
    "    val_dataloader,\n",
    "    train_indices, \n",
    "    val_indices\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:14.569139Z",
     "iopub.execute_input": "2023-11-22T09:04:14.569431Z",
     "iopub.status.idle": "2023-11-22T09:04:14.578305Z",
     "shell.execute_reply.started": "2023-11-22T09:04:14.569401Z",
     "shell.execute_reply": "2023-11-22T09:04:14.577522Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.fit()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-22T09:04:14.579676Z",
     "iopub.execute_input": "2023-11-22T09:04:14.579930Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "Epoch [1/10]  Training:  84%|████████▍ | 8535/10109 [05:08<00:55, 28.59batch/s, train_acc=71.875 %, train_loss=0.164]",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
